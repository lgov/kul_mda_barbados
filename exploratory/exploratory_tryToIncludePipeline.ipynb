{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "favorite-amsterdam",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "df = pd.read_excel (r'../data/all_submission_files.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-vermont",
   "metadata": {},
   "source": [
    "Examine the different data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-railway",
   "metadata": {},
   "source": [
    "# Pre-process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-calvin",
   "metadata": {},
   "source": [
    "## drop missing values (remove rows having missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimension of the dataframe:',df.shape)\n",
    "df.dropna(how='any',inplace=True)\n",
    "print('New Dimension of the dataframe:',df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-encounter",
   "metadata": {},
   "source": [
    "One row is deleted due to missing values in the columns nameofIssuer and titleOfClass. <br/>Print the first 10 rows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-polymer",
   "metadata": {},
   "source": [
    "## Data Formatting, Creating New Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-shepherd",
   "metadata": {},
   "source": [
    "Delete extra columns, make the data homogenous and create a new column \"value_per_share\" for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class OutletTypeEncoder(BaseEstimator):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, documents, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        df['cusip'] = df['cusip'].str.upper()\n",
    "        df['value_per_share'] = df['value'] / df['sshPrnamt']\n",
    "        df['value_log'] = df['value'].apply(lambda x: np.log(x) if x != 0 else 0)\n",
    "        df['sshPrnamt_log'] = df['sshPrnamt'].apply(lambda x: np.log(x) if x != 0 else 0)\n",
    "        df['valuePerShare_log'] = df['value_per_share'].apply(lambda x: np.log(x) if x != 0 else 0)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process = ColumnTransformer(remainder='passthrough',\n",
    "                                transformers=[('drop_columns', 'drop', ['titleOfClass','sshPrnamtType',])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-trick",
   "metadata": {},
   "source": [
    "Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = Pipeline(steps=[('CreateAndUnique',OutletTypeEncoder()),\n",
    "                                ('pre_processing',pre_process)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-housing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-occasion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['value_per_share'] = np.where(df['sshPrnamtType']=='SH',((df['value']*1000)/df['sshPrnamt']),\n",
    "#                                  np.where(df['sshPrnamtType']=='PRN',df['sshPrnamt'], 0))\n",
    "\n",
    "\n",
    "#   ***Where to put above lines?\n",
    "df['value_per_share'] = df['value'] / df['sshPrnamt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-convertible",
   "metadata": {},
   "source": [
    "descriptive statistics of the numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-retailer",
   "metadata": {},
   "source": [
    "It seems that the same concept is never represented in different ways so we don't need to manipulate them. Here, \"cik\" column is also presented but this has no meaning, so can ignore this column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-sussex",
   "metadata": {},
   "source": [
    " # Normalisation (also included in the pipeline)\n",
    " The data frame used here is not formatted due to the operation includes in pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-switzerland",
   "metadata": {},
   "source": [
    "Trying to plot histograms for data in columns 'sshPrnamt' and 'values'. Both cannot be ploted, so listed value_counts() in the following to see the distribution of the data in those two columns. The distribution of the data seems skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sshPrnamt'].hist(bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sshPrnamt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-complex",
   "metadata": {},
   "source": [
    "Because of the skewed characteristics of the data in columns, we copy the columns \"sshPrnamt\",\"value\" and \"value_per_share\" and normalise them by log scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value_log'] = df['value'].apply(lambda x: np.log(x) if x != 0 else 0)\n",
    "df['value_log'].hist(bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sshPrnamt_log'] = df['sshPrnamt'].apply(lambda x: np.log(x) if x != 0 else 0)\n",
    "df['sshPrnamt_log'].hist(bins=15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['valuePerShare_log'] = df['value_per_share'].apply(lambda x: np.log(x) if x != 0 else 0)\n",
    "df['valuePerShare_log'].hist(bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-reminder",
   "metadata": {},
   "source": [
    "Separate 'report_end_date' into Year, Month and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = pd.DatetimeIndex(df['report_end_date']).year\n",
    "df['Month'] = pd.DatetimeIndex(df['report_end_date']).month\n",
    "df['day'] = pd.DatetimeIndex(df['report_end_date']).day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-opposition",
   "metadata": {},
   "source": [
    "Make dataframes according to year for annual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {f'df{i}': d for i, (g, d) in enumerate(df.groupby('Year'))}\n",
    "print(df_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-campus",
   "metadata": {},
   "source": [
    "Histograms for \"ciks\" in 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dict['df0']['cik'].unique())\n",
    "df_dict['df0']['cik'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-match",
   "metadata": {},
   "source": [
    "Histograms for \"ciks\" in 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dict['df1']['cik'].unique())\n",
    "df_dict['df1']['cik'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-softball",
   "metadata": {},
   "source": [
    "Histograms for \"ciks\" in 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dict['df2']['cik'].unique())\n",
    "df_dict['df2']['cik'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-hammer",
   "metadata": {},
   "source": [
    "Histograms for \"ciks\" in 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dict['df3']['cik'].unique())\n",
    "df_dict['df3']['cik'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-message",
   "metadata": {},
   "source": [
    "Histograms for \"ciks\" in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dict['df4']['cik'].unique())\n",
    "df_dict['df4']['cik'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-discovery",
   "metadata": {},
   "source": [
    "Histograms for \"ciks\" in 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dict['df5']['cik'].unique())\n",
    "df_dict['df5']['cik'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-float",
   "metadata": {},
   "source": [
    "Histograms for \"ciks\" in 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dict['df6']['cik'].unique())\n",
    "df_dict['df6']['cik'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-tennessee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
